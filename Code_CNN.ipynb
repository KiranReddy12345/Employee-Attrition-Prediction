{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fb7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec11109",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalData_df      =  pd.read_csv(\"C:/Users/raja/general_data.csv\")\n",
    "employee_survey_df  =  pd.read_csv(\"C:/Users/raja/employee_survey_data.csv\")\n",
    "manager_survey_df   =  pd.read_csv(\"C:/Users/raja/manager_survey_data.csv\")\n",
    "intime_df           =  pd.read_csv(\"C:/Users/raja/in_time.csv\")\n",
    "outtime_df          =  pd.read_csv(\"C:/Users/raja/out_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973aa769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.merge(generalData_df,employee_survey_df,on='EmployeeID')\n",
    "final_df=pd.merge(df1,manager_survey_df,on='EmployeeID')\n",
    "\n",
    "if(len(final_df.columns.tolist())   == (len(generalData_df.columns.tolist()) + len(employee_survey_df.columns.tolist()) + len(manager_survey_df.columns.tolist())) - 2):\n",
    "  print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.isnull().sum().sum())\n",
    "final_df.dropna(inplace=True)\n",
    "print(final_df.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cca79",
   "metadata": {},
   "source": [
    "Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea95397",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_dupliactedRows=final_df[final_df.duplicated( keep=False)].shape[0]\n",
    "if(final_df_dupliactedRows==0):\n",
    "  print(\"there is No duplicate elements in Final_df\")\n",
    "else:\n",
    "  print(\"there is  duplicate elements in Final_df\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334a664",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7ad46",
   "metadata": {},
   "source": [
    "We will cover how to visually analyze: <br>\n",
    "Numerical variables with histograms,<br>\n",
    "Categorical variables with count plots,<br>\n",
    "Relationships between numerical variables with scatter plots, joint plots, and pair plots, and<br>\n",
    "Relationships between numerical and categorical variables with box-and-whisker plots and complex conditional plots.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all columns doing countplots\n",
    "fig = plt.figure(figsize=(26,30))\n",
    "for idx,i in enumerate(final_df.columns.tolist()):\n",
    "    ax=plt.subplot(8,4,idx+1)\n",
    "    sns.countplot(x=i,data=final_df,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92612b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into NumericalColumns\n",
    "columns=final_df.columns.tolist()\n",
    "num_col_eda=['Age','DistanceFromHome','PercentSalaryHike','MonthlyIncome','TotalWorkingYears','YearsAtCompany']\n",
    "final_df[num_col_eda].hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbec63",
   "metadata": {},
   "source": [
    "Output ::\n",
    "\n",
    "1. Key Observation from Above Plot are\n",
    "   -Except Age most of the Columns are in Skew Distribistion form\n",
    "   -Age Feature Distribution is almost Normal Distribution\n",
    "2. As logistic regression does not require independent variables to be normal distributed .so i am not changing distribution of features which are skewed into the normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044092d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrition=num_col_eda+['Attrition']\n",
    "education=['Below-College','College','Bachelor','Master','Doctor']\n",
    "environmentsatisfaction=['Low','Medium','High','Very High']\n",
    "jobinvolvement=['Low','Medium','High','Very High']\n",
    "jobsatisfaction=['Low','Medium','High','Very High']\n",
    "relationshipsatisfaction=['Low','Medium','High','Very High']\n",
    "performancerating=['Low','Good','Excellent','Outstanding']\n",
    "worklifebalance=['Bad','Good','Better','Best']\n",
    "\n",
    "val=[education,environmentsatisfaction,jobinvolvement,jobsatisfaction,performancerating,worklifebalance]\n",
    "cat1=['Education','EnvironmentSatisfaction','JobInvolvement','JobSatisfaction','PerformanceRating','WorkLifeBalance']\n",
    "\n",
    "cat_col_eda=set(columns) - set(num_col_eda)\n",
    "cat_col_eda=set(cat_col_eda) - set(cat1)\n",
    "fig = plt.figure(figsize=(16,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. chaning nums as x_ticks to   categorys as x_ticks\n",
    "fig = plt.figure(figsize=(30,28))\n",
    "for idx,i in enumerate(zip(cat1,val)):\n",
    "    #crosstab = pd.crosstab(index=final_df[i[0]], columns=final_df[\"Attrition\"])\n",
    "    ax=plt.subplot(6,4,idx+1)\n",
    "    #crosstab.plot(kind=\"bar\",stacked=True,ax=ax)\n",
    "    #sns.countplot(x=i[0],data=final_df,ax=ax)\n",
    "    sns.countplot(final_df[i[0]],hue=final_df['Attrition'],ax=ax)\n",
    "    ax.set(xticks=range(len(i[1])), xticklabels=[j for j in i[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d808aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into CategoricalColumns\n",
    "#1. with categorys as x_ticks\n",
    "fig = plt.figure(figsize=(20,26))\n",
    "for idx,i in enumerate(cat_col_eda):\n",
    "    crosstab = pd.crosstab(index=final_df[i], columns=final_df[\"Attrition\"])\n",
    "    ax=plt.subplot(6,4,idx+1)\n",
    "    crosstab.plot(kind=\"bar\",stacked=True,ax=ax)\n",
    "    #sns.countplot(x=i[0],data=final_df,ax=ax)\n",
    "    #ax.set(xticks=range(len(i[1])), xticklabels=[j for j in i[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e875b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #2. chaning nums as x_ticks to   categorys as x_ticks\n",
    "fig = plt.figure(figsize=(20,26))\n",
    "for idx,i in enumerate(zip(cat1,val)):\n",
    "    crosstab = pd.crosstab(index=final_df[i[0]], columns=final_df[\"Attrition\"])\n",
    "    ax=plt.subplot(6,4,idx+1)\n",
    "    crosstab.plot(kind=\"bar\",stacked=True,ax=ax)\n",
    "    #sns.countplot(x=i[0],data=final_df,ax=ax)\n",
    "    ax.set(xticks=range(len(i[1])), xticklabels=[j for j in i[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in num_attrition:\n",
    "fig = plt.figure(figsize=(20,26))\n",
    "for idx,i in enumerate(num_attrition):\n",
    "  crosstab = pd.crosstab(index=final_df[i], columns=final_df[\"Attrition\"])\n",
    "  ax=plt.subplot(6,4,idx+1)\n",
    "    #sns.boxplot(x=i,data=final_df,ax=ax)\n",
    "  \n",
    "  crosstab.plot(kind=\"bar\",stacked=True,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cfbd8",
   "metadata": {},
   "source": [
    "# OUTLIER Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e31966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot for finding \"Outiler\" in our data\n",
    "fig = plt.figure(figsize=(20,26))\n",
    "for idx,i in enumerate(num_col_eda):\n",
    "    ax=plt.subplot(6,4,idx+1)\n",
    "    sns.boxplot(x=i,data=final_df,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b696f4",
   "metadata": {},
   "source": [
    "Results from Above Graph:\n",
    "from above BoxPlot<br> Trying to find is there any outliers in Numerical columns <br>\n",
    "can Observe outliers on MonthlyIncome , TotalWorkingYears and YearsAtCompany Columns<br>\n",
    "from observing on that columns can say those columns some of values not outliers Because there is highly possibilites on<br> occuring those numerical values on those features or columns<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50816e",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b198eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c364dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['age_fs1']=final_df['Age'].map(lambda x: \"20-40\" if(x<40) else \"40-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f24c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(final_df[\"age_fs1\"],hue=final_df['Attrition'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c38ea2",
   "metadata": {},
   "source": [
    "# Finding Coorelation\n",
    "## Corelation on Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))         # Sample figsize in inches\n",
    "\n",
    "sns.heatmap(final_df.corr(),cmap='YlOrRd',linewidths=.5,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c155e63",
   "metadata": {},
   "source": [
    "### There is is no higher dependency between column to columns from above heatMap Plot\n",
    "Categorical Varibles Coorelation ::\n",
    "ChiSquare Test for Independence ::\n",
    "Hypothesis Testing Conditions ::\n",
    "Our hypotheses will be:\n",
    "\n",
    "Null Hypothesis (H0)\n",
    "\n",
    "H0 :: There is no relationship between 2 categorival varibles ie .. Both features or varibles are independent of each other\n",
    "Alternate Hypothesis (H1)\n",
    "\n",
    "H1 :: There is Relationship between 2 categorical varibles .ie .. Both features or varibles are independent of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4aeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=[i for i in final_df.columns.tolist() if(final_df[i].dtype==object)]\n",
    "categorical.remove(\"Over18\")\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import chi2\n",
    "results=[]\n",
    "lst=[]\n",
    "#final=[]\n",
    "input_features=[]\n",
    "chisqr_result=[]\n",
    "for i in categorical:\n",
    "  #print(\"*\"*6 + i + \"*\"*6)\n",
    "    final=[]\n",
    "    for j in categorical:\n",
    "    #print(\"*\"*6 + j + \"*\"*6)\n",
    "    #print(\"*\"*6 + i +\"--\" + j + \"*\"*6)\n",
    "    #Contingency Table\n",
    "        contingency_table=pd.crosstab(final_df[i],final_df[j])\n",
    "    #print('contingency_table :-\\n',contingency_table)\n",
    "    \n",
    "    #Observed Values\n",
    "        Observed_Values = contingency_table.values\n",
    "    #print(\"Observed Values :-\\n\",Observed_Values)\n",
    "    \n",
    "    #Expected Values\n",
    "    #import scipy.stats\n",
    "        b=scipy.stats.chi2_contingency(contingency_table)\n",
    "        Expected_Values = b[3]\n",
    "    #print(\"Expected Values :-\\n\",Expected_Values)\n",
    "\n",
    "\n",
    "    #Degree of Freedom\n",
    "        no_of_rows=Observed_Values.shape[0]\n",
    "        no_of_columns=Observed_Values.shape[1]\n",
    "        df=(no_of_rows-1)*(no_of_columns-1)\n",
    "    #print(\"Degree of Freedom:-\",df)\n",
    "\n",
    "    #Significance Level 5%\n",
    "        alpha=0.05\n",
    "\n",
    "\n",
    "    #chi-square statistic - Ï‡2\n",
    "    #from scipy.stats import chi2\n",
    "        chi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\n",
    "        chi_square_statistic=chi_square[0]+chi_square[1]\n",
    "    #print(\"chi-square statistic:-\",chi_square_statistic)\n",
    "\n",
    "\n",
    "    #critical_value\n",
    "        critical_value=chi2.ppf(q=1-alpha,df=df)\n",
    "    #print('critical_value:',critical_value)\n",
    "\n",
    "    #p-value\n",
    "        p_value=1-chi2.cdf(x=chi_square_statistic,df=df)\n",
    "    #print('p-value:',p_value)\n",
    "\n",
    "\n",
    "    #print('Significance level: ',alpha)\n",
    "    #print('Degree of Freedom: ',df)\n",
    "    #print('chi-square statistic:',chi_square_statistic)\n",
    "    #print('critical_value:',critical_value)\n",
    "    #print('p-value:',p_value)\n",
    "    \n",
    "    #lst1=[df,chi_square_statistic,critical_value,p_value]\n",
    "        lst1=[df,chi_square_statistic,p_value]\n",
    "    \n",
    "    #compare chi_square_statistic with critical_value and p-value which is the probability of getting chi-square>0.09 (chi_square_statistic)\n",
    "        if(chi_square_statistic>=critical_value):\n",
    "      #print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "          test_stat=1\n",
    "        else:\n",
    "      #print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
    "          test_stat=0\n",
    "    \n",
    "        if(p_value<=alpha):\n",
    "        ##print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "            p_val=1\n",
    "        else:\n",
    "        #print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
    "            p_val=0\n",
    "        \n",
    "        if((test_stat==1) and (p_val==1) ):\n",
    "              final_output=1\n",
    "        else:\n",
    "              final_output=0\n",
    "    \n",
    "        lst.append(lst1)\n",
    "        final.append(final_output)\n",
    "        input_features.append((i,j))\n",
    "    \n",
    "    \n",
    "    results.append(lst)\n",
    "    chisqr_result.append(final)\n",
    "\n",
    "print(input_features) \n",
    "print(results)\n",
    "print(chisqr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap\n",
    "sns.heatmap(chisqr_result, \n",
    "        xticklabels=categorical,\n",
    "        yticklabels=categorical,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131637cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "attrition_lable=final_df['Attrition']\n",
    "final_df=final_df.drop('Attrition',1)\n",
    "\n",
    "attrition_lable=attrition_lable.map(lambda x : 1 if(x=='Yes') else 0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df,attrition_lable,test_size=0.20,stratify=attrition_lable, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02db3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#foe i in [X_train,X_cv,X_test]:\n",
    "X_train=pd.get_dummies(X_train)\n",
    "X_test=pd.get_dummies(X_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ml = DecisionTreeClassifier()\n",
    "ml.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69806a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b16c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe527db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375fc57e",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "1) The performance of developed model is excellent and it can be deployed to predict future employee attrition.\n",
    "\n",
    "2) We found a lot of insights about employee attrition during EDA.\n",
    "\n",
    "3) Few major caused of employee attrition includes human resource work, bad work life balance, frequent travels and unmarried employees. So, in order to reduce attrition company should focus on these reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81787008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3206df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d030685",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(X_test)\n",
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "testaccuracy = accuracy_score(y_test, predict_test)\n",
    "print('accuracy_score on test dataset : ', testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_test, predict_test )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8413c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our model\n",
    "testsensitivity= TP / float(TP+FN)\n",
    "testsensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "testspecificity= TN / float(TN+FP)\n",
    "testspecificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b039eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting Attrition when customer does not have Attrited\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46505f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Data Accuracy     :{} %\".format(round((testaccuracy*100),2)))\n",
    "print(\"Test Data Sensitivity  :{} %\".format(round((testsensitivity*100),2)))\n",
    "print(\"Test Data Specificity  :{} %\".format(round((testspecificity*100),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Support Vector Classifier\"\n",
    "from sklearn.svm import SVC  \n",
    "clf = SVC(kernel='linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386becc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_clf = clf.predict(X_test)\n",
    "predict_test_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae144522",
   "metadata": {},
   "outputs": [],
   "source": [
    "testaccuracy_clf = accuracy_score(y_test, predict_test_clf)\n",
    "print('accuracy_score on test dataset : ', testaccuracy_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "K = []\n",
    "training = []\n",
    "test = []\n",
    "scores = {}\n",
    "  \n",
    "for k in range(2, 21):\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train, y_train)\n",
    "  \n",
    "    training_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    K.append(k)\n",
    "  \n",
    "    training.append(training_score)\n",
    "    test.append(test_score)\n",
    "    scores[k] = [training_score, test_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87856a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys, values in scores.items():\n",
    "    print(keys, ':', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.stripplot(K, test);\n",
    "ax.set(xlabel ='values of k', ylabel ='Test Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d18982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "final_df[\"BusinessTravel\"] = le.fit_transform(final_df[\"BusinessTravel\"])\n",
    "final_df[\"Department\"] = le.fit_transform(final_df[\"Department\"])\n",
    "final_df[\"EducationField\"] = le.fit_transform(final_df[\"EducationField\"])\n",
    "final_df[\"Gender\"] = le.fit_transform(final_df[\"Gender\"])\n",
    "final_df[\"Attrition\"] = le.fit_transform(final_df[\"Attrition\"])\n",
    "final_df[\"JobRole\"] = le.fit_transform(final_df[\"JobRole\"])\n",
    "final_df[\"MaritalStatus\"] = le.fit_transform(final_df[\"MaritalStatus\"])\n",
    "final_df[\"Over18\"] = le.fit_transform(final_df[\"Over18\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061c95d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize \n",
    "X_normalized=normalize(final_df1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7c177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length=len(final_df1)\n",
    "train_length=int(0.8*total_length)\n",
    "test_length=int(0.2*total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26d1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_normalized[:train_length]\n",
    "X_test=X_normalized[train_length:]\n",
    "y_train=attrition_lable1[:train_length]\n",
    "y_test=attrition_lable1[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c12a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train (3440, 2)\n",
      "Shape of y_test (860, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train=np_utils.to_categorical(y_train,num_classes=2)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=2)\n",
    "print(\"Shape of y_train\",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c42deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network module\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8248d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1000,input_dim=28,activation='relu'))\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0e96330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1000)              29000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 680,402\n",
      "Trainable params: 680,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a4c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 5s 8ms/step - loss: 0.4552 - accuracy: 0.8328 - val_loss: 0.4131 - val_accuracy: 0.8465\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8363 - val_loss: 0.3940 - val_accuracy: 0.8465\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.4072 - accuracy: 0.8363 - val_loss: 0.3862 - val_accuracy: 0.8465\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8410 - val_loss: 0.3841 - val_accuracy: 0.8453\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3933 - accuracy: 0.8448 - val_loss: 0.3777 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3884 - accuracy: 0.8477 - val_loss: 0.3952 - val_accuracy: 0.8477\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8459 - val_loss: 0.4068 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.8500 - val_loss: 0.3945 - val_accuracy: 0.8384\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8404 - val_loss: 0.3844 - val_accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.3795 - accuracy: 0.8433 - val_loss: 0.3903 - val_accuracy: 0.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26bd9a23970>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=20,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62fcff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the dataset 85.11627906976744\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the dataset\",accuracy )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
